

# 大文件语义划分构建知识图谱

## 前人工作

**思路：**

1.文件按页切片(经验选择页数，如5页/片)

2.构建Prompt，给出限制并让其进行层次划分并输出指定格式的提取json文件

3.Json合并

**帮助：**

1.构建了完善的claude交互框架

2.许多Prompt例子以及注意事项

3.良好的代码规范

4.claude使用tips

**与本项目差异**：

1.**规模量问题**：李若萱的项目做的是小文本量的处理工作（10页），我的是大文本量的处理工作（300页）。我们的文本量较大，除了消耗问题，在他的任务中，上下文的处理是在一个对话中的，而我们的token使用如果在同一个对话中，一定会超。

2.**切片与切片合并**：她的项目是通过文档页数做，然后页与页之间合并。但是她也提到了，目前在跨页面的文本段落处理的不是很理想，而我们的知识，很多都是跨页面的，合并会变得很困难。

3.**输出格式**：她的项目是通过普通的规定格式的直接输出，而我们每本书的输出深度都不固定，每一片的输出格式也不固定，可以说不能这么做。

## 知识图谱构建

我们目标不是最后的内容，而是通过文本分割出对应的知识点结构，因此轻知识点描述重记录描述位置

**知识点实体**：知识模块（通常来说是大标题互相之间不依赖，表现为内部知识点依赖，eg:单元名），知识点（通常来说是次标题以及自然段中需要详细区分）

**知识点关系**：从属（模块到点），依赖、拓展、递进、共生、案例（点对点）

**知识点描述**：内容概述+定位

**伪代码**：

```python
PDF #书
entity #实体 (名字，类型，描述，位置)
relationship #关系(知识点(主)，关系,知识点(宾))
MD=OCR(PDF) #将PDF通过ocr提取，保留原加粗格式，转成具有层级格式的MarkDown大纲树(暂时用字典表示),和他对应的深度（这里要考虑到eg6.1.2的情况）
pos=0
def textSemanticSegmentation(text,pos):
    prompt#让LLM从大段文本进行一个实体识别，给出实体、关系
    response=LLM(text)#实体、关系字典
	entity.append(response['entity'])
    relationship.append(response['relationship'])

def recursionMD(MD,pos):
    for unit in MD:
        entity.append((unit,"知识点","",pos))
        if instance(MD[unit])=="dict":
    		pos=recursionMD(MD[unit],pos)
        else:
           	textSemanticSegmentation(MD[unit],pos)
            pos=pos+len(MD) 
   	return pos

for unit in MD:
    entity.append((unit,"模块","",pos))
	pos=recursionMD(MD[unit],pos)
KGbuild(entity,relationship)
```

## 胡思乱想

1、知识图谱的搜索效率比传统的文本快

2、知识图谱适应思维链编程

3、知识图谱天然没有上下文结构，适合大模型进行检索

4、训练是基于上下文最大化概率训练模型，大多一致性幻觉来源与此，此外这种也会影响知识的召回率，是否有一种可能能在知识图谱或者更高级的语义表示上，去训练一个大模型
